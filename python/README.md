### 机器学习笔记

- 决策树
    - 信息熵越小代表属性越纯
    - ID3：选择信息增益越大的属性作为节点进行划分，信息增益偏好取值较多的属性
    - C4.5：信息增益率偏好取值较少的属性，往往增益率越大越好，但并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。
    - CART：采用基尼系数，Gini(D)反应了数据集D中随机抽取两个样本，其类别标记不一致的概率，因此，Gini(D)越小，则数据集D的纯度越高。
    - 连续值与离散值不同，若当前节点划分属性为连续属性，该属性还可作为其后代节点的划分属性，而离散值则不能。最简单的连续值处理方法是采用二分法对连续值进行处理。
